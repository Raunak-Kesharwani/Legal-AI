{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c128d92-c14f-4afd-80b8-8e14bf599622",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyBTES_Rk5N14ctPN4JJTspiHfccfVO42xA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc8ce4f-3618-49c0-ba38-871346c0ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f737dc-9b7f-4521-b409-d62494d1158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = file_path\n",
    "\n",
    "    def _check_file_type(self):\n",
    "        return self.path.split(\".\")[-1].lower()\n",
    "\n",
    "    def load(self):\n",
    "        ext = self._check_file_type()\n",
    "\n",
    "        if ext == \"pdf\":\n",
    "            loader = PyPDFLoader(self.path)\n",
    "        elif ext == \"txt\":\n",
    "            loader = TextLoader(self.path, encoding=\"utf-8\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "        return loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a0f3da-8060-4a6f-9a12-6ddb7eb137e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSplitter:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "\n",
    "    def summary_split(self):\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2500,\n",
    "            chunk_overlap=150\n",
    "        )\n",
    "        return splitter.split_text(self.text)\n",
    "\n",
    "    def embed_split(self):\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size= 1200,\n",
    "            chunk_overlap=150\n",
    "        )\n",
    "        return splitter.split_documents(self.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a27574-168e-4229-b88b-27d4075acf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class ChunkLegalResponse(BaseModel):\n",
    "    Summary: str = Field(\n",
    "        description=\"Detailed summary of this section\"\n",
    "    )\n",
    "    Flag: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Risky clause if present\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FinalLegalResponse(BaseModel):\n",
    "    Summary: str = Field(\n",
    "        min_length=300,\n",
    "        description=\"Full multi-paragraph legal summary\"\n",
    "    )\n",
    "    Flag: Optional[str] = Field(\n",
    "        description=\"Most significant risky clause for bearer\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49271ce9-1da8-4850-afd6-584556ba1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatModel:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api = api_key\n",
    "\n",
    "    def get_chat_model(self):\n",
    "        return ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-pro\", \n",
    "            google_api_key=self.api,\n",
    "            temperature=0.4,\n",
    "            max_tokens=2000\n",
    "        )\n",
    "\n",
    "    def get_embed_model(self):\n",
    "        return GoogleGenerativeAIEmbeddings(\n",
    "            model = \"gemini-embedding-001\",\n",
    "            api_key=self.api,\n",
    "            output_dimensionality=512\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d88365-2d90-44ab-a855-f9cb2b46b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chunk_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "You are a legal document analysis assistant.\n",
    "\n",
    "Analyze ONLY the provided text segment.\n",
    "\n",
    "Tasks:\n",
    "1. Produce a detailed legal summary of this segment.\n",
    "2. Identify any clause that may be risky or harmful to the bearer.\n",
    "\n",
    "Rules:\n",
    "- Do not infer beyond the given text.\n",
    "- If no risky clause exists, explicitly say so.\n",
    "- Preserve exact legal language where relevant.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b02ff5-ee1c-438b-9372-d924dcc0836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "You are a senior legal analyst.\n",
    "\n",
    "You are given multiple legal summaries and identified risks\n",
    "from different sections of the same document.\n",
    "\n",
    "Tasks:\n",
    "1. Produce a cohesive, multi-paragraph legal summary of the ENTIRE document.\n",
    "2. Identify the SINGLE most significant risky clause affecting the bearer.\n",
    "3. If multiple risks exist, choose the most severe.\n",
    "4. If no risks exist, state this clearly.\n",
    "\n",
    "Return output strictly in the required JSON format.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d880968a-6ccf-4145-a7b9-f87e75840024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_chunks(chunks: List[str], max_chunks: int = 9) -> List[str]:\n",
    "    \"\"\"\n",
    "    Limit the number of chunks to at most max_chunks\n",
    "    by evenly sampling across the document.\n",
    "    \"\"\"\n",
    "    if len(chunks) <= max_chunks:\n",
    "        return chunks\n",
    "\n",
    "    step = max(1, len(chunks) // max_chunks)\n",
    "    return [chunks[i] for i in range(0, len(chunks), step)][:max_chunks]\n",
    "\n",
    "\n",
    "def truncate_text(text: str, max_chars: int = 8000) -> str:\n",
    "    \"\"\"\n",
    "    Prevent silent LLM failures by bounding input size.\n",
    "    \"\"\"\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    return text[:max_chars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8cd81cc-cbe8-432c-9b30-1141af1f0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegalSummarizer:\n",
    "    def __init__(self, model, text: str):\n",
    "        self.base_model = model\n",
    "        self.text = text\n",
    "\n",
    "    def summarize(self) -> FinalLegalResponse:\n",
    "        chunks = TextSplitter(self.text).summary_split()\n",
    "\n",
    "        chunks = cap_chunks(chunks, max_chunks=9)\n",
    "\n",
    "        chunk_model = self.base_model.with_structured_output(ChunkLegalResponse)\n",
    "\n",
    "        chunk_results = []\n",
    "        for chunk in chunks:\n",
    "            result = (chunk_prompt | chunk_model).invoke(\n",
    "                {\"text\": chunk}\n",
    "            )\n",
    "            chunk_results.append(result)\n",
    "\n",
    "        merged_input = \"\\n\\n\".join(\n",
    "        f\"SUMMARY:\\n{r.Summary}\\nRISK:\\n{r.Flag or 'None'}\"\n",
    "        for r in chunk_results\n",
    "        )\n",
    "\n",
    "        merged_input = truncate_text(merged_input, max_chars=8000)\n",
    "\n",
    "\n",
    "        final_model = self.base_model.with_structured_output(FinalLegalResponse)\n",
    "\n",
    "        final_result = (merge_prompt | final_model).invoke(\n",
    "            {\"text\": merged_input}\n",
    "        )\n",
    "\n",
    "        return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be1c70e-3eb7-45a7-a5b8-5731f62c9456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL SUMMARY =====\n",
      "\n",
      "This document outlines a Deed of Lease, a contractual agreement between a Lessor (property owner) and a Lessee (tenant) for a specified property. The lease is established for a multi-year term commencing in 2000, in exchange for a fixed monthly ground rent. The payment terms are strict, requiring the Lessee to pay the rent in advance by the 5th of each month, free of all deductions. Failure to pay on time incurs an interest penalty, though payment of this interest does not formally excuse the default, leaving the Lessee vulnerable to further remedies by the Lessor.\n",
      "\n",
      "The agreement places a significant number of obligations on the Lessee. Beyond rent, the Lessee is responsible for bearing all existing and future rates, taxes, and assessments on the property, and must indemnify the Lessor against these costs. While the Lessee is required to keep the property in good repair, they are granted the right to demolish existing structures and erect new ones, provided they do not sell or excavate materials like earth or sand from the premises. Conversely, the Lessor covenants to provide the Lessee with \"quiet enjoyment\" of the property, contingent upon the Lessee's adherence to all lease terms.\n",
      "\n",
      "The Lessor retains substantial power to terminate the agreement. The lease can be determined if the rent is in arrears, if the Lessee breaches other covenants and fails to remedy them after notice, or, most notably, if the Lessee raises any objection to the amount of the monthly rent. The agreement also contains critical provisions regarding the end of the lease term. The Lessee is restricted from assigning, mortgaging, or subletting the property without the Lessor's written consent. Critically, upon the expiration or earlier termination of the lease, all buildings and structures constructed by the Lessee on the land automatically transfer to the Lessor's ownership without any form of compensation.\n",
      "\n",
      "===== RISK FLAG =====\n",
      "\n",
      "Clause 5.a is the most significant risk, as it dictates that upon the lease's termination, 'all the buildings and structures standing on the demised land shall automatically vest in the Lessor without payment of any compensation therefor by the Lessor to the Lessee.' This clause forces the Lessee to forfeit the entire value of any capital improvements or buildings they construct, representing a potentially catastrophic financial loss of their investment at the end of the lease.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = DataLoader(\"sample-doc/sample_rent_doc.txt\").load()\n",
    "\n",
    "text = \"\\n\".join(doc.page_content for doc in docs)\n",
    "text\n",
    "\n",
    "\n",
    "model = ChatModel(api_key=GOOGLE_API_KEY).get_chat_model()\n",
    "\n",
    "summarizer = LegalSummarizer(model, text)\n",
    "result = summarizer.summarize()\n",
    "\n",
    "print(\"\\n===== FINAL SUMMARY =====\\n\")\n",
    "print(result.Summary)\n",
    "\n",
    "print(\"\\n===== RISK FLAG =====\\n\")\n",
    "print(result.Flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea6911c-5966-4f56-bd96-5a99712e49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "memory_store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8f5f1-aca6-4155-8440-2061878b60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ThreadManager:\n",
    "    def __init__(self):\n",
    "        self.store = {}\n",
    "\n",
    "    def create_thread(self):\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        self.store[thread_id] = []\n",
    "        return thread_id\n",
    "\n",
    "    def add_message(self, thread_id, role, content):\n",
    "        self.store[thread_id].append({\n",
    "            \"role\": role,\n",
    "            \"content\": content\n",
    "        })\n",
    "\n",
    "    def get_history(self, thread_id):\n",
    "        return self.store.get(thread_id, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9898df8d-dd5e-4ead-b2b5-81e5a1d3a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('ce724b07-b7cd-4813-826a-86945b9db4ba')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe56a84c-91e3-4bf7-8911-54b5419419d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffabd6a-bf90-433d-a116-3cd22c30f03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df44ceb-9caf-456d-a3e6-8575581259bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
